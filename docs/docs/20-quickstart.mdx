---
description: Kargo Quickstart
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Quickstart

This guide presents a basic introduction to Kargo. Together, we will:

1. Create a local Kubernetes cluster.

1. Install Kargo's dependencies, including Argo CD.

1. Install Kargo itself with default options.

1. Demonstrate how Kargo can progress changes through multiple stages by
   interacting with your GitOps repository and Argo CD `Application` resources.

1. Clean up.

## Prerequisites

* [Docker](https://www.docker.com/)
* [kind](https://kind.sigs.k8s.io/) or [k3d](https://k3d.io/): These
  instructions were tested with:
    * kind: v0.17.0
    * k3d: v5.4.9
* [Helm](https://helm.sh/docs/): These instructions were tested with v3.11.2.

### Starting a Local Cluster

We will start our cluster using options that make it convenient to access the
Argo CD dashboard and three different instances of our demo application on
different `localhost` ports:

<Tabs groupId="cluster-start">
<TabItem value="kind" label="kind">

```shell
kind create cluster \
  --wait 120s \
  --config - <<EOF
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
name: kargo-quickstart
nodes:
- extraPortMappings:
  - containerPort: 30080 # Argo CD dashboard
    hostPort: 8080
  - containerPort: 30081 # test application instance
    hostPort: 8081
  - containerPort: 30082 # UAT application instance
    hostPort: 8082
  - containerPort: 30083 # prod application instance
    hostPort: 8083
  - containerPort: 30084 # Kargo dashboard
    hostPort: 8084
EOF
```

</TabItem>
<TabItem value="k3d" label="k3d">

```shell
k3d cluster create kargo-quickstart \
  --no-lb \
  --k3s-arg '--disable=traefik@server:0' \
  -p '8080-8084:30080-30084@servers:0:direct' \
  --wait
```

</TabItem>
</Tabs>

### Installing `cert-manager`
:::info
In its default configuration, Kargo uses `cert-manager` to provision a self-signed
certificate for use by Kargo's webhook server. In a more advanced installation,
you may optionally disregard this dependency by providing a certificate yourself
through any means you prefer.
:::

```shell
helm install cert-manager cert-manager \
  --repo https://charts.jetstack.io \
  --version 1.11.5 \
  --namespace cert-manager \
  --create-namespace \
  --set installCRDs=true \
  --wait
```

### Installing Argo CD

:::info
Kargo works best when integrated with Argo CD, but we're working on reducing
this dependency from a required one to a suggested one.
:::

```shell
helm install argocd argo-cd \
  --repo https://argoproj.github.io/argo-helm \
  --version 5.46.6 \
  --namespace argocd \
  --create-namespace \
  --set 'configs.secret.argocdServerAdminPassword=$2a$10$5vm8wXaSdbuff0m9l21JdevzXBzJFPCi8sy6OOnpZMAG.fOXL7jvO' \
  --set dex.enabled=false \
  --set notifications.enabled=false \
  --set server.service.type=NodePort \
  --set server.service.nodePortHttp=30080 \
  --wait
```

The Argo CD dashboard will be accessible at
[localhost:8080](http://localhost:8080).

You can safely ignore cert errors.

The username and password are both `admin`.

## Installing Kargo

```shell
helm install kargo \
  oci://ghcr.io/akuity/kargo-charts/kargo \
  --version 0.1.0-rc.21 \
  --namespace kargo \
  --create-namespace \
  --set api.service.type=NodePort \
  --set api.service.nodePort=30084 \
  --set 'api.adminAccount.password=admin' \
  --wait
```

The Kargo dashboard will be accessible at
[localhost:8084](http://localhost:8084).

The Admin password is `admin`.

## Trying It Out

### Create a GitOps Repository

In this step, we will create a GitOps repo on GitHub to house variations of our
application manifests for three different stages: test, UAT, and
production.

Visit https://github.com/akuity/kargo-demo and fork the repository into your own
GitHub account.

You can explore the repository and see that the `main` branch contains common
configuration in a `base/` directory as well as stage-specific overlays in
paths of the form `stages/<stage name>/`. [Kustomize](https://kustomize.io/)
is used as a configuration management tool that combines base configuration with
stage-specific configuration.

:::note
This layout is typical of a GitOps repository using Kustomize and is not at all
Kargo-specific.
:::

### Create Argo CD `Application`s

In this step, we will create three Argo CD `Application` resources that deploy
the same application at three different stages of its lifecycle, with three
slightly different configurations, to three different namespaces in our local
cluster.

To get started, you will require a GitHub [personal access
token](https://github.com/settings/tokens) with adequate permissions to read
from and write to the repository you forked in the previous section.

1. Save the location of your GitOps repository, your GitHub handle, and your
   personal access token in environment variables:

   ```shell
   export GITOPS_REPO_URL=<your repo URL, starting with https://>
   export GITHUB_USERNAME=<your github handle>
   export GITHUB_PAT=<your personal access token>
   ```

1. Create namespaces for each of our three stages, a `Secret` containing
   repository credentials, and Argo CD `Application` resources for each stage:

   ```shell
   cat <<EOF | kubectl apply -f -
   apiVersion: v1
   kind: Namespace
   metadata:
     name: kargo-demo-test
   ---
   apiVersion: v1
   kind: Namespace
   metadata:
     name: kargo-demo-uat
   ---
   apiVersion: v1
   kind: Namespace
   metadata:
     name: kargo-demo-prod
   ---
   apiVersion: v1
   kind: Secret
   type: Opaque
   metadata:
     name: kargo-demo-repo
     namespace: argocd
     labels:
       argocd.argoproj.io/secret-type: repository
     annotations:
       kargo.akuity.io/authorized-projects: kargo-demo
   stringData:
     type: git
     project: default
     url: ${GITOPS_REPO_URL}
     username: ${GITHUB_USERNAME}
     password: ${GITHUB_PAT}
   ---
   apiVersion: argoproj.io/v1alpha1
   kind: Application
   metadata:
     name: kargo-demo-test
     namespace: argocd
     annotations:
       kargo.akuity.io/authorized-stage: kargo-demo:test
   spec:
     project: default
     source:
       repoURL: ${GITOPS_REPO_URL}
       targetRevision: main
       path: stages/test
     destination:
       server: https://kubernetes.default.svc
       namespace: kargo-demo-test
   ---
   apiVersion: argoproj.io/v1alpha1
   kind: Application
   metadata:
     name: kargo-demo-uat
     namespace: argocd
     annotations:
       kargo.akuity.io/authorized-stage: kargo-demo:uat
   spec:
     project: default
     source:
       repoURL: ${GITOPS_REPO_URL}
       targetRevision: main
       path: stages/uat
     destination:
       server: https://kubernetes.default.svc
       namespace: kargo-demo-uat
   ---
   apiVersion: argoproj.io/v1alpha1
   kind: Application
   metadata:
     name: kargo-demo-prod
     namespace: argocd
     annotations:
       kargo.akuity.io/authorized-stage: kargo-demo:prod
   spec:
     project: default
     source:
       repoURL: ${GITOPS_REPO_URL}
       targetRevision: main
       path: stages/prod
     destination:
       server: https://kubernetes.default.svc
       namespace: kargo-demo-prod
   EOF
   ```

If you visit [your Argo CD dashboard](http://localhost:8080), you will notice
all three Argo CD `Application`s have not yet synced because they're not
configured to do so automatically.

:::info
Our three stages all existing in a single cluster is for the sake of
convenience. Because a single Argo CD control plane can manage multiple
clusters, we could just as easily have spread our stages across multiple
clusters/environments.
:::

### Create and Configure a Kargo Project

Up to this point, we haven't done anything with Kargo -- in fact everything
we've done thus far should be familiar to anyone who's already using Argo CD and
Kustomize.

In this step, we'll create a Kargo project (a specially labeled namespace) and
three Kargo `Stage` resources. These can be thought of as a layer "above" your
GitOps repositories and Argo CD `Application`s. Their role is to describe
subscriptions to different materials (like manifests or container images), the
process for applying those materials, and the process for asserting whether they
are properly deployed and healthy. For a simple example, such as ours, this
means:

* Watching the `nginx` image repository for new versions.
* Automating relevant changes to the GitOps repository and affected Argo CD
  `Application` resources.
* Monitoring the health and sync state of Argo CD `Application` resources.

We will also create two `PromotionPolicy` resources that will express
permission for new materials to be deployed _automatically_ to the
`kargo-demo-test` and `kargo-demo-uat` stages and one `RoleBinding` to grant
permission for members of the `system:masters` group to promote new materials
_manually_ to any of the stages. In fact, we will create these `PromotionPolicy`
and `RoleBinding` resources first:

```shell
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Namespace
metadata:
  name: kargo-demo
  labels:
    kargo.akuity.io/project: "true"
---
apiVersion: kargo.akuity.io/v1alpha1
kind: PromotionPolicy
metadata:
  name: test
  namespace: kargo-demo
stage: test
enableAutoPromotion: true
---
apiVersion: kargo.akuity.io/v1alpha1
kind: PromotionPolicy
metadata:
  name: uat
  namespace: kargo-demo
stage: uat
enableAutoPromotion: true
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: promoters
  namespace: kargo-demo
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: kargo-promoter
subjects:
- kind: Group
  name: system:masters
EOF
```

#### The `test` `Stage`

```shell
cat <<EOF | kubectl apply -f -
apiVersion: kargo.akuity.io/v1alpha1
kind: Stage
metadata:
  name: test
  namespace: kargo-demo
spec:
  subscriptions:
    repos:
      images:
      - repoURL: nginx
        semverConstraint: ^1.24.0
  promotionMechanisms:
    gitRepoUpdates:
    - repoURL: ${GITOPS_REPO_URL}
      writeBranch: main
      kustomize:
        images:
        - image: nginx
          path: stages/test
    argoCDAppUpdates:
    - appName: kargo-demo-test
      appNamespace: argocd
EOF
```

Dissecting the manifest above, we see the `test` `Stage` subscribes directly to
the `nginx` image repository. When a new, semantically tagged version of the
`nginx` container image is discovered, Kargo has discovered new _freight_.
Because the corresponding `PromotionPolicy` resource permits auto-promotion, the
discovery of this new freight will immediately result in the creation of a new
`Promotion` resource that will transition the new piece of freight to the `test`
`Stage`.

The actual promotion process involves running `kustomize edit set image` on the
`stages/test` directory of our GitOps repository and committing those changes,
then forcing the `kargo-demo-test` Argo CD `Application` to refresh and sync.

After creating the `test` `Stage` resource, we should almost immediately see:

1. The `test` `Stage` has been assigned a current freight and is healthy:

   ```text
   kubectl get stage test --namespace kargo-demo
   ```

  ```text
   NAME   CURRENT FREIGHT                            HEALTH    AGE
   test   d9a3e3e54b11b3e4a763e7cb8b1098089b567686   Healthy   30s
   ```

1. The `test` `Stage` resource's `status` field reflects the available freight,
   the current freight, and the history of freight that has moved through this
   `Stage`:

   ```text
   kubectl get stage test \
     --namespace kargo-demo \
     --output jsonpath-as-json={.status}
   ```

1. A `Promotion` resource was also created which was responsible for
   transitioning the new piece of freight into the `test` `Stage`.

   ```texts
   kubectl get promotions --namespace kargo-demo
   ```

   ```text
   NAME                                               STAGE   FREIGHT                                    PHASE       AGE
   test-to-d9a3e3e54b11b3e4a763e7cb8b1098089b567686   test    d9a3e3e54b11b3e4a763e7cb8b1098089b567686   Succeeded   55s
   ```

1. Your GitOps repository has a new commit.

1. [Your Argo CD dashboard](http://localhost:8080) shows that `kargo-demo-test`
   `Application` is synced and healthy.

   The test instance of Nginx is visible at
   [localhost:8081](http://localhost:8081).

#### The `uat` `Stage`

```shell
cat <<EOF | kubectl apply -f -
apiVersion: kargo.akuity.io/v1alpha1
kind: Stage
metadata:
  name: uat
  namespace: kargo-demo
spec:
  subscriptions:
    upstreamStages:
    - name: test
  promotionMechanisms:
    gitRepoUpdates:
    - repoURL: ${GITOPS_REPO_URL}
      writeBranch: main
      kustomize:
        images:
        - image: nginx
          path: stages/uat
    argoCDAppUpdates:
    - appName: kargo-demo-uat
      appNamespace: argocd
EOF
```

Dissecting the manifest above, we see the `uat` `Stage` is somewhat different
from the `test` `Stage` in that it does not find new freight by subscribing
directly to an image repository, but discovers freight by monitoring the
"upstream" `test` `Stage`. Any healthy piece of freight from the `test` `Stage`'s
`history` field becomes available freight for the `uat` `Stage`. Because the
corresponding `PromotionPolicy` resource permits auto-promotion, the discovery
of the `test` `Stage`'s current, healthy freight immediately results in the
creation of a new `Promotion` resource to move that freight into this `Stage`.

The `promotionMechanisms` for the `uat` `Stage` are not substantially different
from those for the `test` `Stage`. They involve running `kustomize edit set
image` on the `stages/uat` directory of our GitOps repository and committing
those changes, then forcing the `kargo-demo-uat` Argo CD `Application` to
refresh and sync.

After creating the `uat` `Stage` resource, we should almost immediately
see:

1. The `uat` `Stage` has been assigned a current freight and is healthy:

   ```shell
   kubectl get stage uat --namespace kargo-demo
   ```

   ```text
   NAME    CURRENT FREIGHT                            HEALTH    AGE
   stage   d9a3e3e54b11b3e4a763e7cb8b1098089b567686   Healthy   13s
   ```

1. The `uat` `Stage` resource's `status` field reflects the available freight,
   the current freight, and the history of all freight that has moved through
   this `Stage`:

   ```shell
   kubectl get stage uat \
     --namespace kargo-demo \
     --output jsonpath-as-json={.status}
   ```

1. A `Promotion` resource was created which was responsible for moving the one
   available piece of freight into the `uat` `Stage`.

   ```shell
   kubectl get promotions --namespace kargo-demo
   ```

   ```
   NAME                                               STAGE   FREIGHT                                    PHASE       AGE
   test-to-d9a3e3e54b11b3e4a763e7cb8b1098089b567686   test    d9a3e3e54b11b3e4a763e7cb8b1098089b567686   Succeeded   2m40s
   uat-to-d9a3e3e54b11b3e4a763e7cb8b1098089b567686    uat     d9a3e3e54b11b3e4a763e7cb8b1098089b567686   Succeeded   43s
   ```

1. [Your Argo CD dashboard](http://localhost:8080) shows that `kargo-demo-uat`
   `Application` is synced and healthy.

   The UAT instance of Nginx is visible at
   [localhost:8082](http://localhost:8082).

#### The `prod` `Stage`

```shell
cat <<EOF | kubectl apply -f -
apiVersion: kargo.akuity.io/v1alpha1
kind: Stage
metadata:
  name: prod
  namespace: kargo-demo
spec:
  subscriptions:
    upstreamStages:
    - name: uat
  promotionMechanisms:
    gitRepoUpdates:
    - repoURL: ${GITOPS_REPO_URL}
      writeBranch: main
      kustomize:
        images:
        - image: nginx
          path: stages/prod
    argoCDAppUpdates:
    - appName: kargo-demo-prod
      appNamespace: argocd
EOF
```

Dissecting the manifest above, we see the `prod` `Stage` is remarkably similar
to the `uat` `Stage`. It discovers new freight by monitoring the "upstream"
`uat` `Stage`. Any healthy freight from the `uat` `Stage`'s `history` field
becomes available freight for the `prod` `Stage`.

The `promotionMechanisms` for the `prod` `Stage` also are not substantially
different from those for either the `test` or `uat` `Stage`s. They involve
running `kustomize edit set image` on the `stages/prod` directory of our GitOps
repository and committing those changes, then forcing the `kargo-demo-prod` Argo
CD `Application` to refresh and sync.

Because the corresponding `PromotionPolicy` resource does _not_ permit
auto-promotion, no `Promotion` resource will be automatically created.

After creating the `prod` `Stage` resource, we should almost immediately see:

1. The `prod` `Stage` has not yet been assigned a current freight:

   ```shell
   kubectl get stage prod --namespace kargo-demo
   ```

   ```text
   NAME   CURRENT FREIGHT   HEALTH   AGE
   prod                            12s
   ```

1. The `prod` `Stage` resource's `status` field reflects the one available
   piece of freight, but shows no current freight or history:

   ```shell
   kubectl get stage prod \
     --namespace kargo-demo \
     --output jsonpath-as-json={.status}
   ```

1. No `Promotion` resource was automatically created to transition the freight
   into the `prod` `Stage`.

   ```shell
   kubectl get promotions --namespace kargo-demo
   ```

   ```
   NAME                                               STAGE   FREIGHT                                    PHASE       AGE
   test-to-d9a3e3e54b11b3e4a763e7cb8b1098089b567686   test    d9a3e3e54b11b3e4a763e7cb8b1098089b567686   Succeeded   4m4s
   uat-to-d9a3e3e54b11b3e4a763e7cb8b1098089b567686    uat     d9a3e3e54b11b3e4a763e7cb8b1098089b567686   Succeeded   2m7s
   ```

1. [Your Argo CD dashboard](http://localhost:8080) shows that `kargo-demo-prod`
   `Application` is _still_ not synced and healthy.

### Trigger a Promotion to the `prod` `Stage`

In this step, we will trigger a promotion to transition the new freight into the
`prod` `Stage` by manually creating a `Promotion` resource.

First, copy the ID of the `uat` `Stage`'s current freight and assign it to a
`FREIGHT_ID` environment variable:

```shell
export FREIGHT_ID=$(kubectl get stage uat -n kargo-demo -o jsonpath={.status.currentFreight.id})
```

Then apply the following:

```shell
cat <<EOF | kubectl apply -f -
apiVersion: kargo.akuity.io/v1alpha1
kind: Promotion
metadata:
  name: prod-to-${FREIGHT_ID}
  namespace: kargo-demo
spec:
  stage: prod
  freight: ${FREIGHT_ID}
EOF
```

After a few moments, we should be able to see:

1. The `Promotion` has succeeded:

   ```shell
   kubectl get promotions --namespace kargo-demo
   ```

   ```text
   NAME                                               STAGE   FREIGHT                                    PHASE       AGE
   prod-to-d9a3e3e54b11b3e4a763e7cb8b1098089b567686   prod    d9a3e3e54b11b3e4a763e7cb8b1098089b567686   Succeeded   12s
   test-to-d9a3e3e54b11b3e4a763e7cb8b1098089b567686   test    d9a3e3e54b11b3e4a763e7cb8b1098089b567686   Succeeded   8m11s
   uat-to-d9a3e3e54b11b3e4a763e7cb8b1098089b567686    uat     d9a3e3e54b11b3e4a763e7cb8b1098089b567686   Succeeded   6m14ss
   ```

1. The `prod` `Stage` has now been assigned a current freight:

   ```shell
   kubectl get stage prod --namespace kargo-demo
   ```

   ```text
   NAME   CURRENT FREIGHT                            HEALTH    AGE
   prod   d9a3e3e54b11b3e4a763e7cb8b1098089b567686   Healthy   5m20s
   ```

1. The `prod` `Stage` resource's `status` field reflects the available freight,
   the current freight, and the history of all freight that has moved through
   this `Stage`:

   ```text
   kubectl get stage prod \
     --namespace kargo-demo \
     --output jsonpath-as-json={.status}
   ```

1. [Your Argo CD dashboard](http://localhost:8080) shows that `kargo-demo-prod`
   `Application` is now not synced and healthy.

   The prod instance of Nginx is visible at
   [localhost:8083](http://localhost:8083).

## Summary

At this point, if a new semantically tagged version of the `nginx` image should
be pushed to Docker Hub, it will _automatically_ be discovered and promoted into
our test stage, followed shortly thereafter by promotion into our UAT stage.
Upon reaching the UAT stage, it will become available for manual promotion to
production.

This has been a "hello world"-level introduction to Kargo, demonstrating only
the most basic functionality. Much more complex and useful promotion patterns
are also possible and you are invited to continue exploring the documentation
to learn more!

## Cleaning up

To clean up, we will simply destroy our kind or k3d cluster:

<Tabs groupId="cluster-start">
<TabItem value="kind" label="kind">

```shell
kind delete cluster --name kargo-quickstart
```

</TabItem>
<TabItem value="k3d" label="k3d">

```shell
k3d cluster delete kargo-quickstart
```

</TabItem>
</Tabs>
